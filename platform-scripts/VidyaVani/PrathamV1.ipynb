{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "Concept Map populated\n",
      "................\n",
      "Content Model populated\n",
      "................\n",
      "Content popularity score updated\n"
     ]
    }
   ],
   "source": [
    "# mocks the data for Pratham usecase V1 and recommends content based on content popularity\n",
    "import csv\n",
    "import sys\n",
    "import collections\n",
    "import os.path\n",
    "import requests\n",
    "\n",
    "# on exit clean-ups\n",
    "import atexit\n",
    "\n",
    "# cassandra libs\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import dict_factory\n",
    "\n",
    "\n",
    "# neo4j libs\n",
    "from py2neo import Graph\n",
    "from py2neo import Node, Relationship\n",
    "from py2neo import authenticate\n",
    "from random import randint\n",
    "from numpy import np\n",
    "\n",
    "# neo4j graph connector\n",
    "authenticate(\"localhost:7474\", \"neo4j\", \"1sTep123\")\n",
    "graph = Graph()\n",
    "# delete entire graph\n",
    "#graph.delete_all()\n",
    "\n",
    "\n",
    "\n",
    "# bool flag database connections\n",
    "cassandraDbOn=False\n",
    "neo4jDbOn=False\n",
    "ASERdict_num={1:\"ASERlevel_Beginner\",2:\"ASERlevel_Addition\",3:\"ASERlevel_Subtraction\",4:\"ASERlevel_Multiplication\",5:\"ASERlevel_Division\"}\n",
    "ASERdict_lit={1:\"ASERlevel_Beginner\",2:\"ASERlevel_Letter\",3:\"ASERlevel_Word\",4:\"ASERlevel_Sentence\",5:\"ASERlevel_Paragraph\"}\n",
    "def dbCleanUP(cassandraDbOn,neo4jDbOn):\n",
    "    if cassandraDbOn:\n",
    "    \tprint 'cleaning Cassandra state'\n",
    "    \tsession.shutdown();\n",
    "    \tcluster.shutdown();\n",
    "\n",
    "atexit.register(dbCleanUP,True,True)\n",
    "\n",
    "# setup cassandra connection\n",
    "cassandraDbOn=True\n",
    "cluster = Cluster()\n",
    "session = cluster.connect('learner_db')\n",
    "\n",
    "# set response schema to Dictionaries\n",
    "session.row_factory = dict_factory\n",
    "\n",
    "# process learner-db\n",
    "# move content summary table\n",
    "def movecontentsideloadingsummary():\n",
    "    graph = Graph()\n",
    "\n",
    "    cids = session.execute(\"SELECT DISTINCT content_id from content_sideloading_summary\")\n",
    "    for cid in cids:\n",
    "        uid = cid['content_id']\n",
    "        print(\"** Content:\",uid)\n",
    "\n",
    "        node=Node(\"Content\",id=uid)\n",
    "        graph.merge(node,\"Content\",\"id\")\n",
    "\n",
    "        contentDict = session.execute(\"SELECT * from content_sideloading_summary WHERE id='\" + uid + \"'\")[0]\n",
    "        cid = contentDict['content_id']\n",
    "        \n",
    "        #if (contentDict.has_key('total_count')):\n",
    "        #    total_count = contentDict['total_count']\n",
    "        #    node.properties['content_popularity'] = total_count\n",
    "        #    node.push()\n",
    "        node.properties['content_popularity'] = randint(1,100)\n",
    "        node.push()\n",
    "        \n",
    "        print('content: ', cid, 'content_popularity: ',total_count)\n",
    "\n",
    "# move concept map \n",
    "def moveConceptMap():\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    # delete entire graph\n",
    "\n",
    "    url=\"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/domain/map\"\n",
    "    resp = requests.get(url).json()\n",
    "\n",
    "    # move all concepts\n",
    "    conceptList = resp[\"result\"][\"concepts\"]\n",
    "    for conceptDict in conceptList:\n",
    "        identifier=None\n",
    "    \n",
    "        if(not conceptDict.has_key('identifier')):\n",
    "            continue\n",
    "\n",
    "        identifier = conceptDict['identifier']\n",
    "        # create/find node\n",
    "        node = graph.merge_one(\"Concept\",\"id\",identifier)\n",
    "\n",
    "        if(conceptDict.has_key('subject')):\n",
    "            subject = conceptDict['subject']\n",
    "            node.properties[\"subject\"]=subject\n",
    "            node.push()\n",
    "\n",
    "        if(conceptDict.has_key('objectType')):\n",
    "            objectType = conceptDict['objectType']\n",
    "            node.properties[\"objectType\"]=objectType\n",
    "            node.push()\n",
    "       \n",
    "        if(subject.lower()=='numeracy'):\n",
    "            node.properties['tags'] = str(ASERdict_num[randint(1,5)])\n",
    "        if(subject.lower()=='literacy'):\n",
    "            node.properties['tags'] = str(ASERdict_lit[randint(1,5)])\n",
    "        node.push()\n",
    "        \n",
    "        # move all relations\n",
    "        relationList = resp[\"result\"][\"relations\"]\n",
    "    for relationDict in relationList:\n",
    "\n",
    "        if (not relationDict.has_key('startNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('endNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('relationType') ):\n",
    "            continue\n",
    "        startNodeId = relationDict['startNodeId']\n",
    "        endNodeId = relationDict['endNodeId']\n",
    "        relationType = relationDict['relationType']\n",
    "        node1 = graph.merge_one(\"Concept\",\"id\",startNodeId)\n",
    "        node2 = graph.merge_one(\"Concept\",\"id\",endNodeId)\n",
    "        graph.create(Relationship(node1, relationType, node2))\n",
    "\n",
    "def moveContentModel():\n",
    "    baseURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/getContent/\"\n",
    "    listURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/content/list\"\n",
    "\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    \n",
    "    url = listURL\n",
    "    resp = requests.get(url).json()\n",
    "    # no of content\n",
    "    contentList = resp[\"result\"][\"contents\"]\n",
    "    for contentListDict in contentList:\n",
    "        # check if there is an identifier for this content\n",
    "        if(not contentListDict.has_key('identifier')):\n",
    "            continue\n",
    "    \n",
    "        # check if there is an identifier for this content\n",
    "        identifier = contentListDict['identifier']\n",
    "\n",
    "        # create a node for this Content\n",
    "        node = graph.merge_one(\"Content\",\"id\",identifier)\n",
    "       \n",
    "        url = baseURL + identifier\n",
    "        resp = requests.get(url)\n",
    "\n",
    "        if(resp.status_code!=200):\n",
    "            continue\n",
    "\n",
    "        resp =  resp.json()\n",
    "\n",
    "        concept=None\n",
    "        Subject=None\n",
    "        content_popularity=None\n",
    "        \n",
    "        contentDict = resp[\"result\"][\"content\"]\n",
    "\n",
    "    \n",
    "        if(contentDict.has_key('concepts')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            concepts = contentDict['concepts']\n",
    "        \n",
    "        if(contentDict.has_key('Subject')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            Subject = contentDict['Subject']\n",
    "            node.properties['Subject'] = Subject\n",
    "            node.push()\n",
    "            if(Subject.lower()=='numeracy'):\n",
    "                node.properties['tags'] = str(ASERdict_num[randint(1,5)])\n",
    "            if(Subject.lower()=='literacy'):\n",
    "                node.properties['tags'] = str(ASERdict_lit[randint(1,5)])\n",
    "            node.push()\n",
    "            \n",
    "        #node.properties['tags'] = \"ASERlevel_\"+str(randint(1,5))\n",
    "        #node.push()\n",
    "       \n",
    "   \n",
    "        #updating content popularity as a tag\n",
    "        node.properties['content_popularity'] = randint(1,100)\n",
    "        node.push()\n",
    "\n",
    "print('................')\n",
    "#moveConceptMap();\n",
    "print('Concept Map populated')\n",
    "# content model\n",
    "print('................')\n",
    "moveContentModel();\n",
    "print('Content Model populated')\n",
    "print('................')\n",
    "#movecontentsideloadingsummary();\n",
    "print('Content popularity score updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomended content for ASER level match:\n",
      "(['numeracy_374', 'org.ekstep.numchart.worksheet',\n",
      "       'org.ekstep.addobj.worksheet', 'org.ekstep.counting.worksheet',\n",
      "       'org.ekstep.eng.num.activity', 'numeracy_365', 'numeracy_366',\n",
      "       'numeracy_418', 'ASERlevel_Subtraction', 'ASERlevel_Subtraction',\n",
      "       'ASERlevel_Multiplication', 'ASERlevel_Multiplication',\n",
      "       'ASERlevel_Division', 'ASERlevel_Division', 'ASERlevel_Division',\n",
      "       'ASERlevel_Division', 'ASERlevel_Division', 'ASERlevel_Addition',\n",
      "       'ASERlevel_Addition'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "sub=\"numeracy\"\n",
    "level=\"ASERlevel_Beginner\"\n",
    "#content for exact match of level\n",
    "query1=\"MATCH (b:Content) WHERE (lower(b.Subject)=~ '(?i)\"+sub+\"') AND ( has(b.tags)) AND ('\"+level+\"' IN (b.tags))  Return b.id AS Content, b.tags AS tag, b.content_popularity AS popularity ORDER BY popularity DESC\"\n",
    "query2=\"MATCH (b:Content) WHERE lower(b.Subject)=~ '(?i)\"+sub+\"' OPTIONAL MATCH (b) WHERE ( has(b.tags)) AND ('\"+level+\"' IN (b.tags))  Return b.id AS Content, b.tags AS tag, b.content_popularity AS popularity ORDER BY tag DESC,popularity DESC\"\n",
    "resp1= graph.cypher.execute(query1)\n",
    "# content for match at domain level-optional match\n",
    "resp2= graph.cypher.execute(query2)\n",
    "resp2_array=np.asarray(resp2)\n",
    "resp2_minusresp1=resp2_array[resp2_array[:,1]!=level,1]\n",
    "#resp1=[]\n",
    "if resp1:\n",
    "    print('Recomended content for ASER level match:')\n",
    "    resp1_content=np.asarray(resp1)[:,0]\n",
    "    print(resp1_content,resp2_minusresp1)\n",
    "else:\n",
    "    print('Recomended content for \\'subject\\' level match :')\n",
    "    print(resp2_minusresp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
