# This is the main configuration file for the application.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
application.secret="DFHdR74?tDvH2n`DAqk:RBl6NfkoO5tNYblTRmf3ZLcDIp5@oVjJM^ypkDOf2`<A"

# The application languages
# ~~~~~
application.langs="en"

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
# application.global=Global

# Router
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point.
# Furthermore, it's assumed your route file is named properly.
# So for an application router like `my.application.Router`,
# you may need to define a router file `conf/my.application.routes`.
# Default to Routes in the root package (and conf/routes)
# application.router=my.application.Routes

# Database configuration
# ~~~~~
# You can declare as many datasources as you want.
# By convention, the default datasource is named `default`
#
# db.default.driver=org.h2.Driver
# db.default.url="jdbc:h2:mem:play"
# db.default.user=sa
# db.default.password=""

# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled

# Logger
# ~~~~~
# You can also configure logback (http://logback.qos.ch/),
# by providing an application-logger.xml file in the conf directory.

# Root logger:
logger.root=ERROR

# Logger used by the framework:
logger.play=INFO

# Logger provided to your application:
logger.application=DEBUG

# Test Configurations
cassandra.service.embedded.enable=false
cassandra.cql_path="../../platform-scripts/database/data.cql"
cassandra.service.embedded.connection.port=9142
cassandra.keyspace_prefix="local_"

spark.cassandra.connection.host="127.0.0.1"
application.env="local"

# Content to vec configurations
content2vec.content_service_url="https://dev.ekstep.in/api/learning"
content2vec.scripts_path="src/test/resources/python/main/vidyavaani"
content2vec.enrich_content="true"
content2vec.train_model="false"
content2vec.content_corpus="true"
content2vec.infer_query="true"
content2vec.s3_bucket="ekstep-dev-data-store"
content2vec.s3_key_prefix="DataSciences/model/"
content2vec.model_path="/tmp/content2vec/model/"
content2vec.kafka_topic="sandbox.learning.graph.events"
content2vec.kafka_broker_list="localhost:9092"
content2vec.infer_all="false"
content2vec.corpus_path="/tmp/content2vec/content_corpus/"
content2vec.download_path="/tmp/content2vec/download/"
content2vec.download_file_prefix="temp_"
content2vec.train_model_job="../../platform-scripts/shell/local/run-job.sh ctv &"
recommendation.train_model_job="../../platform-scripts/shell/local/run-job.sh device-recos &"


# Recommendations configurations
service.search.url="https://dev.ekstep.in/api/search"
service.search.path="/v2/search"
service.search.requestbody="""{"request":{"filters":{"objectType":["Content"],"contentType":["Story","Worksheet","Collection","Game"],"status":["Live"]},"limit":1000}}"""
service.search.limit="10"

recommendation.enable=true
recommendation.limit="10"
recommendation.surprise_find.enable=true
recommendation.surprise_find.index="15"
recommendation.surprise_find.serendipity_factor="20"

dataproduct.scripts_path=../../platform-scripts/shell/local
data.cql_path=../../platform-scripts/database/data.cql

# Metrics API configuration
#metrics.search.type="s3"
#metrics.search.params={"bucket":"ekstep-dev-data-store", "path":"metrics/"}
metrics.search.type="local"
metrics.search.params={"bucket":"", "path":"src/test/resources/metrics/"}
metrics.period.format.day="MMM dd EEE"
metrics.period.format.month="MMM YYYY"
metrics.period.format.year="YYYY"
metrics.creation.es.url="http://localhost:9200"
metrics.creation.es.indexes="compositesearch"
metrics.dialcode.es.indexes="dialcodemetrics"
metrics.dialcode.request.limit=5
# Data Exhaust API
data_exhaust.list.limit="100"
data_exhaust.retry.limit="3"
data_exhaust.dataset.list=["eks-consumption-raw", "eks-consumption-summary", "eks-consumption-metrics","eks-creation-raw", "eks-creation-summary", "eks-creation-metrics"]
data_exhaust.dataset.default="eks-consumption-raw"
data_exhaust.output_format="json"

default.consumption.app.id="no_value"
default.channel.id="in.ekstep"
default.creation.app.id="no_value"

postgres.db="ip2location"
postgres.url="jdbc:postgresql://localhost:5432/"
postgres.user="postgres"
postgres.pass="test10"
postgres.location_table="ip2location_db3"
postgres.table_name="consumer-channel-mapping"

channel.data_exhaust.bucket="ekstep-dev-data-store"
channel.data_exhaust.basePrefix="channel-exhaust/"
channel.data_exhaust.expiryMins=30

storage-service.request-signature-version="AWS4-HMAC-SHA256"
s3service.region="ap-south-1"

storage_type="azure"


#redis.host=__redis_host__
redis.host="localhost"
redis.port=6379
#redis.port=__redis_port__
redis.connection.max=2
redis.connection.idle.max=2
redis.connection.idle.min=1
redis.connection.minEvictableIdleTimeSeconds=120
redis.connection.timeBetweenEvictionRunsSeconds=300
redis.experimentIndex=10

elasticsearch.host="localhost"
elasticsearch.port=9200
elasticsearch.searchExperiment.index="experiment"
elasticsearch.searchExperiment.fieldWeight="{\"userId\":3.0, \"deviceId\":3.0, \"url\":3.0 }"
elasticsearch.searchExperiment.queryWeight=9.0
deviceRegisterAPI.experiment.enable=true
experimentService.redisEmptyValueExpirySeconds=1000

experiment-actor {
  type = "Dispatcher"
  executor = "fork-join-executor"
  fork-join-executor {
    # The parallelism factor is used to determine thread pool size using the
    # following formula: ceil(available processors * factor). Resulting size
    # is then bounded by the parallelism-min and parallelism-max values.
    parallelism-factor = 3.0

    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 8

    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 16
  }
  # Throughput for default Dispatcher, set to 1 for as fair as possible
  throughput = 1
}

druid.coordinator.host="http://11.4.3.41:8081/"
druid.healthcheck.url="druid/coordinator/v1/loadstatus"